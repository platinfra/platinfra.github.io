{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to platinfra","text":"<p><code>platinfra</code> came to be when i started exploring the different tools in mlops space and had the intention of deploying them on the cloud. The idea was to liberate the IaC logic for creating MLOps stacks and accelerate the deployment and decision making process for MLOps engineers so that they can focus where it matters; on choosing the right tooling for their workflows.</p> <p>platinfra allows MLOps and DevOps to deploy different MLOps tools for different stages of the machine learning lifecycle. The magic of platinfra is hidden in the python layer, that reads through the deployment config and deploys all these tools using terraform modules and connects them using dynamically generated set of roles and permissions.</p> <p>platinfra deploys infrastructure using a declarative approach. The minimal spec for aws cloud as infra with custom applications deployed is as follows:</p> <pre><code>name: aws-mlops-stack\nprovider:\n  name: aws\n  account-id: xxxxxxxxx\ndeployment:\n  type: kubernetes\nstack:\n  data_versioning:\n    - dvc # can also be pachyderm or lakefs or neptune and so on\n  experiment_tracker:\n    - mlflow # can be weights and biases or determined, or neptune or clearml and so on...\n  pipelining:\n    - zenml # can also be argo, or luigi, or airflow, or dagster, or prefect or flyte or kubeflow and so on...\n  orchestrator:\n    - aws-batch # can also be aws step functions or aws-fargate or aws-eks or azure-aks and so on...\n  runtime_engine:\n    - ray # can also be horovod or apache spark\n  artifact_tracker:\n    - mlflow # can also be neptune or clearml or lakefs or pachyderm or determined or wandb and so on...\n  # model registry and serving are quite close, need to think about them...\n  model_registry:\n    - bentoml # can also be  mlflow or neptune or determined and so on...\n  model_serving:\n    - nvidia_triton # can also be bentoml or fastapi or cog or ray or seldoncore or tf serving\n  monitoring:\n    - nannyML # can be grafana or alibi or evidently or neptune or mlflow or prometheus or weaveworks and so on...\n  alerting:\n    - mlflow # can be mlflow or neptune or determined or weaveworks or prometheus or grafana and so on...\n</code></pre>"},{"location":"CONTRIBUTING/","title":"Contributing to platinfra","text":"<p>Thank you for your interest in contributing to this project!</p> <p>We appreciate issue reports, pull requests for code and documentation, as well as any project-related communication through discussions.</p>"},{"location":"CONTRIBUTING/#getting-started","title":"Getting Started","text":"<ul> <li>To get started, pat yourself!</li> </ul>"},{"location":"user_guide/how_platinfra_works/","title":"User Guide","text":""},{"location":"user_guide/how_platinfra_works/#how-platinfra-works","title":"How platinfra works","text":"<ul> <li>A sample mlops stack looks something like this:</li> <li>The same stack can be configured to quite an extent:</li> </ul> Simple Deployment ConfigurationAdvanced Deployment Configuration <pre><code>name: simple-mlops-stack\nprovider:\n  name: aws\n  account_id: \"aws-12-digit-account-id\"\n  region: \"aws-region\"\ndeployment:\n  type: cloud_infra\nstack:\n  - data_versioning:\n      name: lakefs\n  - experiment_tracking:\n      name: mlflow\n  - pipelining:\n      name: prefect\n</code></pre> <pre><code>name: simple-mlops-stack-advanced\nprovider:\n  name: aws\n  account_id: \"aws-12-digit-account-id\"\n  region: \"aws-region\"\ndeployment:\n  type: cloud_infra\nstack:\n  - data_versioning:\n      name: lakefs\n      params:\n        remote_tracking: true\n        database_type: \"dynamodb\"\n        lakefs_data_bucket_name: \"lakefs-repository-data-bucket\"\n        dynamodb_table_name: \"lakefs_kvstore\"\n  - experiment_tracking:\n      name: mlflow\n      params:\n        remote_tracking: true\n        mlflow_artifacts_bucket_name: \"artifacts-storage-bucket\"\n  - pipelining:\n      name: prefect\n      params:\n        remote_tracking: true\n        ec2_application_port: 9500\n</code></pre>"},{"location":"user_guide/how_platinfra_works/#stack-file-composition","title":"Stack file Composition","text":"<p><code>platinfra</code> stack file is composed of 4 components:</p> <ul> <li><code>name</code>: <code>name</code> denotes the name of the stack. This is used internally to identify the state of the the stack deployment.</li> <li><code>provider</code> block:<ul> <li><code>provider</code> block allows you to define where your stack gets deployed, whether it be local or on the cloud.</li> <li><code>account_id</code> and <code>region</code> are used to configure the cloud provider.</li> </ul> </li> <li><code>deployment</code> block:<ul> <li><code>deployment</code> block defines the configuration of how the components get configured under the hood before deployment of mlops stack.</li> <li>For now, <code>type</code> can be either <code>cloud_infra</code> or <code>kubernetes</code>. We're working to introduce more deployment types.</li> <li><code>type: cloud_infra</code> is used to deploy the stack to the cloud instances, whereas <code>kubernetes</code> uses cloud provider's kubernetes service to deploy the stack.</li> </ul> </li> <li><code>stack</code> block:<ul> <li><code>stack</code> block defines the different application stacks that are deployed to the above mentioned <code>deployment</code> stack.</li> <li>Each mlops stack is defined by a <code>name</code>. All stacks can be deployed from a simple name configuration to a more complex configuration where different components are   deployed on cloud provider infrastructure components.</li> </ul> </li> </ul>"}]}